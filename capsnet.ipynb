{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras implementation of CapsNet\n",
    "##### `Dynamic Routing Between Capsules` by Sabour, Frosst and Hinton, in NIPS 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLAN:\n",
    "* implement reshaping 3D tensor (output of regular Conv2D into 32 6x6x8 capsules (or preferably, 32 36x8 capsules, so in fact make it (32x36)x8 **DONE**\n",
    "* implement a capsule layer with forward pass = dynamic routing\n",
    "    - implement squash function **DONE**\n",
    "    - implement weight sharing between capsules in each of 32 groups **LOOKS LIKE DONE?** **NEEDS IMPROVEMENT**\n",
    "    - implement dynamic routing **SEEMS DONE, BUT TWICE THERE SEEMS TO BE UNNECESSARY DIMS EXPANSION AND COPYING OF TENSORS. TRY FIXING THIS**\n",
    "* implement margin loss for digit existence\n",
    "* implement reconstruction loss with masking for depending on learning phase\n",
    "* put it all together into a network\n",
    "* train on MNIST with small data augmentation as described in the paper, use `.fit_generator()`\n",
    "* reproduce paper results\n",
    "* visualize some reconstructions\n",
    "* visualize how reconstructions change with continous change of one of DigitCaps dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (6, 6, 256)\n",
    "output_shape = (1152, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_X = np.random.random((input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Reshape, Permute\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this appears correct (numpy)\n",
    "reshape_intermediate = dummy_X.reshape(6, 6, 32, 8)\n",
    "reshape_intermediate_2 = reshape_intermediate.reshape(36, 32, 8)\n",
    "reshaped_3 = reshape_intermediate_2.reshape(1152, 8, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS APPEARS TO WORK CORRECTLY (Keras)\n",
    "\n",
    "input_tensor = Input(shape=input_shape)\n",
    "reshaped = Reshape((36, 32, 8))(input_tensor)\n",
    "permuted = Permute((2,1,3))(reshaped)\n",
    "output_tensor = Reshape(output_shape)(permuted)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)\n",
    "output = model.predict(dummy_X.reshape(1, 6, 6, 256))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23075144,  0.43397957,  0.06308483,  0.90659434,  0.177563  ,\n",
       "        0.55920148,  0.64529717,  0.37560156], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23075145,  0.43397957,  0.06308483,  0.90659436,  0.17756299,\n",
       "        0.55920148,  0.64529719,  0.37560156])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_X[5, 4, -8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CapsNet Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLayer(Layer):\n",
    "    \n",
    "    def __init__(self, output_capsules, capsule_dim, num_groups=None, routing_iterations=3, **kwargs):\n",
    "        self.output_capsules = output_capsules\n",
    "        self.capsule_dim = capsule_dim\n",
    "        self.num_groups = num_groups\n",
    "        self.routing_iterations = routing_iterations\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        if self.num_groups:\n",
    "            if input_shape[1] % self.num_groups:\n",
    "                raise ValueError('num_groups should divide input_shape[0] without remainder')\n",
    "            \n",
    "            # correct this\n",
    "            self.kernel = self.add_weight(\n",
    "                name='kernel', \n",
    "                shape=(\n",
    "                    self.num_groups,\n",
    "                    self.output_capsules,\n",
    "                    input_shape[-1],\n",
    "                    self.capsule_dim\n",
    "                ),\n",
    "                initializer='uniform',\n",
    "                trainable=True\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            self.kernel = self.add_weight(\n",
    "                name='kernel',\n",
    "                shape=(\n",
    "                    input_shape[1], \n",
    "                    self.output_capsules, \n",
    "                    input_shape[2], \n",
    "                    self.capsule_dim,\n",
    "                ),\n",
    "                initializer='uniform',\n",
    "                trainable=True\n",
    "            )\n",
    "        \n",
    "        super(CapsuleLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        # initialize matrix of b_ij's\n",
    "        input_shape = K.shape(x)\n",
    "        B = K.zeros(shape=(input_shape[0], input_shape[1], self.output_capsules))\n",
    "        \n",
    "        x = K.expand_dims(x, axis=2)\n",
    "        x = K.repeat_elements(x, rep=self.output_capsules, axis=2)\n",
    "        U = K.map_fn(lambda x: K.batch_dot(x, self.kernel, axes=[2,2]), x)\n",
    "        \n",
    "        for i in range(self.routing_iterations):\n",
    "            V, B_updated = self._routing_single_iter(B, U, i, input_shape)\n",
    "            B = B_updated\n",
    "            \n",
    "        return V\n",
    "            \n",
    "    def _routing_single_iter(self, B, U, i, input_shape):\n",
    "        C = K.softmax(B, axis=-1)\n",
    "        C = K.expand_dims(C, axis=-1)\n",
    "        C = K.repeat_elements(C, rep=self.capsule_dim, axis=-1)\n",
    "        S = K.sum(C * U, axis=1)\n",
    "        V = self._squash(S)\n",
    "        if i != self.routing_iterations:\n",
    "            V_expanded = K.expand_dims(V, axis=1)\n",
    "            V_expanded = K.tile(V_expanded, [1, input_shape[1], 1, 1])\n",
    "            B = B + K.sum(U*V_expanded, axis=-1)\n",
    "        return V, B\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _squash(x):\n",
    "        l2_norm = K.sum(K.square(x), axis=-1, keepdims=True)\n",
    "        squash = l2_norm / (1 + l2_norm) * (x / (K.sqrt(l2_norm) + K.epsilon()))\n",
    "        return squash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1152, 10, 16)\n",
      "(12, 1152, 10, 16)\n",
      "(12, 1152, 10, 16)\n",
      "(12, 1152, 10)\n"
     ]
    }
   ],
   "source": [
    "B = K.zeros(shape=(12, 1152, 10))\n",
    "C =  K.map_fn(lambda x: K.softmax(x, axis=-1), B)\n",
    "\n",
    "x_batch = K.ones(shape=(12,1152, 8))\n",
    "x_batch = K.expand_dims(x_batch, axis=2)\n",
    "x_batch = K.repeat_elements(x_batch, rep=10, axis=2)\n",
    "y_batch = K.ones(shape=(1152, 10, 8, 16))\n",
    "xy_batch_dot = K.map_fn(lambda x: K.batch_dot(x, y_batch, axes=[2,2]), x_batch)\n",
    "\n",
    "C= K.expand_dims(C, axis=-1)\n",
    "C = K.repeat_elements(C, rep=16, axis=-1)\n",
    "\n",
    "print(K.int_shape(C))\n",
    "print(K.int_shape(xy_batch_dot))\n",
    "\n",
    "S = K.sum(C * xy_batch_dot, axis=1)\n",
    "S = K.expand_dims(S, axis=1)\n",
    "S = K.tile(S, [1,1152,1,1])\n",
    "# S = K.repeat_elements(S, rep=1152, axis=1)\n",
    "\n",
    "print(K.int_shape(S))\n",
    "new_B = K.sum(xy_batch_dot*S, axis=-1 )\n",
    "print(K.int_shape(new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_X = np.random.random((32,6,6,256))\n",
    "\n",
    "input_tensor = Input(shape=input_shape)\n",
    "reshaped = Reshape((36, 32, 8))(input_tensor)\n",
    "permuted = Permute((2,1,3))(reshaped)\n",
    "primary_caps = Reshape(output_shape)(permuted)\n",
    "digit_caps = CapsuleLayer(10, 16)(primary_caps)\n",
    "\n",
    "model = Model(input_tensor, digit_caps)\n",
    "output = model.predict(dummy_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10, 16)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CapsuleLayer(10, 16)\n",
    "c.build((1,1152,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1152, 10, 16)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch = K.ones(shape=(12,1152, 8))\n",
    "x_batch = K.expand_dims(x_batch, axis=2)\n",
    "x_batch = K.repeat_elements(x_batch, rep=10, axis=2)\n",
    "y_batch = K.ones(shape=(1152, 10, 8, 16))\n",
    "xy_batch_dot = K.map_fn(lambda x: K.batch_dot(x, y_batch, axes=[2,2]), x_batch)\n",
    "K.int_shape(xy_batch_dot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
