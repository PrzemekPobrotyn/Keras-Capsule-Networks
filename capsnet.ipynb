{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras implementation of CapsNet\n",
    "##### `Dynamic Routing Between Capsules` by Sabour, Frosst and Hinton, in NIPS 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLAN:\n",
    "* implement reshaping 3D tensor (output of regular Conv2D into 32 6x6x8 capsules (or preferably, 32 36x8 capsules, so in fact make it (32x36)x8 **DONE**\n",
    "* implement a capsule layer with forward pass = dynamic routing\n",
    "    - implement squash function **DONE**\n",
    "    - implement weight sharing between capsules in each of 32 groups **LOOKS LIKE DONE? NO IDEA IF IT WORKS CORRECTLY THOUGH**\n",
    "    - implement dynamic routing **SEEMS DONE, BUT TWICE THERE SEEMS TO BE UNNECESSARY DIMS EXPANSION AND COPYING OF TENSORS. TRY FIXING THIS**\n",
    "* implement margin loss for digit existence **DONE**\n",
    "* implement reconstruction loss with masking for depending on learning phase **DONE**\n",
    "* put it all together into a network **DONE**\n",
    "* train on MNIST with small data augmentation as described in the paper, use `.fit_generator()`\n",
    "* reproduce paper results\n",
    "* visualize some reconstructions\n",
    "* visualize how reconstructions change with continous change of one of DigitCaps dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras import initializers, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Conv2D, Lambda, Dense, Flatten, Reshape\n",
    "from keras.engine.topology import Layer\n",
    "from keras.utils.generic_utils import get_custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32')\n",
    "x_train = x_train / 255.\n",
    "\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32')\n",
    "x_test = x_test / 255.\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 590"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+IGg/h+woUxy9dJ6DAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c40b7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(x_test[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "def capsule_length(x):\n",
    "    return K.sqrt(K.sum(K.square(x), axis=-1))\n",
    "\n",
    "def squash(x):\n",
    "    l2_norm = K.sum(K.square(x), axis=-1, keepdims=True)\n",
    "    squash = l2_norm / (1 + l2_norm) * (x / (K.sqrt(l2_norm + K.epsilon())))\n",
    "    return squash\n",
    "\n",
    "get_custom_objects().update({'squash': Activation(squash)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses\n",
    "\n",
    "def margin_loss(lambda_=0.5, m_plus=0.9, m_minus=0.1):\n",
    "    def margin(y_true, y_pred):\n",
    "        loss = K.sum(\n",
    "            y_true * K.square(K.maximum(0., m_plus - y_pred)) + \n",
    "            lambda_ * (1 - y_true) * K.square(K.maximum(0., y_pred - m_minus)),\n",
    "            axis=1,\n",
    "        )\n",
    "        return loss\n",
    "    return margin\n",
    "\n",
    "def reconstruction_loss(y_true, y_pred):\n",
    "    return K.sum(K.square(y_true  - y_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrimaryCaps(\n",
    "    capsule_dim,\n",
    "    filters,\n",
    "    kernel_size, \n",
    "    strides=(1,1),\n",
    "    padding='valid',\n",
    "):\n",
    "    \n",
    "    conv2d = Conv2D(\n",
    "            filters=filters, \n",
    "            kernel_size=kernel_size, \n",
    "            strides=strides, \n",
    "            padding=padding)\n",
    "    \n",
    "    def eval_primary_caps(input_tensor):\n",
    "        \n",
    "#         nonlocal conv2d\n",
    "        x = conv2d(input_tensor)\n",
    "        reshaped = Reshape((-1, capsule_dim))(x)\n",
    "        return Lambda(squash)(reshaped)\n",
    "\n",
    "    return eval_primary_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLayer(Layer):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        output_capsules, \n",
    "        capsule_dim, \n",
    "        routing_iterations=3, \n",
    "        kernel_initializer='glorot_uniform',\n",
    "        activation='squash',\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.output_capsules = output_capsules\n",
    "        self.capsule_dim = capsule_dim\n",
    "        self.routing_iterations = routing_iterations\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.activation=Activation(activation)\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=(\n",
    "                self.output_capsules,\n",
    "                input_shape[1],\n",
    "                self.capsule_dim,\n",
    "                input_shape[2],\n",
    "            ),\n",
    "            initializer=self.kernel_initializer,\n",
    "            trainable=True,\n",
    "        )\n",
    "        \n",
    "        super(CapsuleLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        input_shape = K.shape(x)\n",
    "        x = K.expand_dims(x, axis=1)\n",
    "        x_tiled = K.tile(x, [1, self.output_capsules, 1, 1])\n",
    "        U = K.map_fn(lambda x: K.batch_dot(x, self.kernel, axes=[2,3]), elems=x_tiled)\n",
    "        \n",
    "        # initialize matrix of b_ij's\n",
    "        B = K.zeros(shape=(input_shape[0], self.output_capsules, input_shape[1]))\n",
    "        for i in range(self.routing_iterations):\n",
    "            V, B_updated = self._routing_single_iter(B, U, i)\n",
    "            B = B_updated\n",
    "            \n",
    "        return V\n",
    "            \n",
    "    def _routing_single_iter(self, B, U, i):\n",
    "        C = K.softmax(B, axis=1)\n",
    "        S = K.batch_dot(C, U, [2, 2])\n",
    "        V = self.activation(S)\n",
    "        if i < self.routing_iterations - 1:\n",
    "            B = B + K.batch_dot(V, U, [2, 3])\n",
    "        return V, B\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.output_capsules, self.capsule_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructionMask(Layer):\n",
    "    def call(self, input_):\n",
    "        if type(input_) == list and len(input_) == 2:\n",
    "            x, mask = input_[0], input_[1]\n",
    "        else:\n",
    "            x = input_\n",
    "            len_x = K.sqrt(K.sum(K.square(x), -1))\n",
    "            mask = K.one_hot(indices=K.argmax(len_x, 1), num_classes=K.shape(x)[1])\n",
    "        \n",
    "        return K.batch_flatten(x * K.expand_dims(mask, -1))\n",
    "    \n",
    "    \n",
    "    def compute_output_shape(self, input_):\n",
    "        if type(input_) == list and len(input_) == 2:\n",
    "            input_shape = input_[0]\n",
    "            return (None, input_shape[1] * input_shape[2])\n",
    "        else:\n",
    "            return (None, input_[1] * input_[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_capsule_network(input_shape=(28, 28, 1)):\n",
    "    \n",
    "    # encoder network\n",
    "    input_tensor = Input(shape=input_shape, dtype='float32', name='data')\n",
    "    conv1 = Conv2D(kernel_size=(9,9), strides=(1,1), filters=256, activation='relu')(input_tensor)\n",
    "#     primary_caps = PrimaryCaps(capsule_dim=8, filters=256, kernel_size=(9,9), strides=(2,2))(conv1)\n",
    "    \n",
    "    primary_caps = Conv2D(filters=256, \n",
    "            kernel_size=9, \n",
    "            strides=2)(conv1)\n",
    "    primary_caps = Reshape((-1, 8))(primary_caps)\n",
    "    primary_caps = Lambda(squash)(primary_caps)\n",
    "    capsule_layer = CapsuleLayer(output_capsules=10, capsule_dim=16)(primary_caps)\n",
    "    lengths = Lambda(capsule_length, output_shape=(10,), name='digits')(capsule_layer)\n",
    "    \n",
    "    input_mask = Input(shape=(10,), name='mask')\n",
    "    masked_from_labels = ReconstructionMask()([capsule_layer, input_mask])\n",
    "    masked_by_length = ReconstructionMask()(capsule_layer)\n",
    "  \n",
    "    # decoder network\n",
    "    decoder = Sequential(name='decoder')\n",
    "    decoder.add(Dense(512, activation='relu', input_shape=(160,)))\n",
    "    decoder.add(Dense(1024, activation='relu'))\n",
    "    decoder.add(Dense(784, activation='sigmoid'))\n",
    "    decoder.add(Reshape(input_shape))\n",
    "    \n",
    "    training_model = Model(input_tensor, lengths)\n",
    "#     training_model = Model([input_tensor, input_mask], [lengths, decoder(masked_from_labels)])\n",
    "    inference_model = Model(input_tensor, [lengths, decoder(masked_by_length)])\n",
    "\n",
    "    return training_model, inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsnet_train, capsnet_inference = get_capsule_network()\n",
    "\n",
    "dummy_X = np.random.random((1, 28, 28, 1))\n",
    "dummy_mask = np.array([0]*9 + [1]).reshape(1, 10)\n",
    "output_train = capsnet_train.predict(dummy_X)\n",
    "# output_inference = capsnet_inference.predict(dummy_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.08482810e-08,   6.19953511e-08,   8.55215490e-08,\n",
       "          8.55084608e-08,   6.00604793e-08,   5.53650139e-08,\n",
       "          1.30817924e-07,   1.44476445e-07,   1.41975349e-07,\n",
       "          9.94171074e-08]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "data (InputLayer)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 256)       20992     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 256)         5308672   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1152, 8)           0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 1152, 8)           0         \n",
      "_________________________________________________________________\n",
      "capsule_layer_1 (CapsuleLaye (None, 10, 16)            1474560   \n",
      "_________________________________________________________________\n",
      "digits (Lambda)              (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 6,804,224\n",
      "Trainable params: 6,804,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "capsnet_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.56874e-05\n",
      "0.00980886\n",
      "(9, 9, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(capsnet_train.get_weights()[i].mean())\n",
    "print(capsnet_train.get_weights()[i].std())\n",
    "print(capsnet_train.get_weights()[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " 8576/60000 [===>..........................] - ETA: 31:44 - loss: 0.3386 - acc: 0.6206"
     ]
    }
   ],
   "source": [
    "# capsnet_train.compile(\n",
    "#     loss={'digits': margin_loss(), 'decoder': reconstruction_loss},\n",
    "#     loss_weights={'digits': 1, 'decoder':0.0005}, \n",
    "#     optimizer='adam',\n",
    "#     metrics={'digits': 'acc'}\n",
    "# )\n",
    "\n",
    "\n",
    "capsnet_train.compile(\n",
    "    loss=margin_loss(),\n",
    "    optimizer='adam',\n",
    "    metrics={'digits': 'acc'}\n",
    ")\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def train_generator(x, y, batch_size, shift_fraction=0.):\n",
    "    train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "                                       height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
    "    generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "    while 1:\n",
    "        x_batch, y_batch = generator.next()\n",
    "#         yield x_batch, y_batch\n",
    "#         yield ([x_batch, y_batch], [y_batch, x_batch])\n",
    "\n",
    "# capsnet_train.fit_generator(generator=train_generator(x_train, y_train, 100, 0.),\n",
    "#                     steps_per_epoch=int(y_train.shape[0] / 100),\n",
    "#                     epochs=10,\n",
    "#                     validation_data=[[x_test, y_test], [y_test, x_test]])\n",
    "\n",
    "\n",
    "# capsnet_train.fit([x_train, y_train], [y_train, x_train], epochs=10, batch_size=128, validation_data=([x_test, y_test], [y_test, x_test]))\n",
    "capsnet_train.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000177686\n",
      "0.0124434\n",
      "(10, 1152, 16, 8)\n"
     ]
    }
   ],
   "source": [
    "i=4\n",
    "print(capsnet_train.get_weights()[i].mean())\n",
    "print(capsnet_train.get_weights()[i].std())\n",
    "print(capsnet_train.get_weights()[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = K.ones((2, 10, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = K.eval(x)\n",
    "squashed = K.eval(squash(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_squash(x):\n",
    "    l2_norm = np.sum(x**2, axis=-1, keepdims=True)\n",
    "    scalar = l2_norm /(1 + l2_norm) / np.sqrt(l2_norm +1e-7)\n",
    "    return x * scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23529412,  0.23529412,  0.23529412,  0.23529412,  0.23529412,\n",
       "        0.23529412,  0.23529412,  0.23529412,  0.23529412,  0.23529412,\n",
       "        0.23529412,  0.23529412,  0.23529412,  0.23529412,  0.23529412,\n",
       "        0.23529412], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_squash(x_)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23529415,  0.23529415,  0.23529415,  0.23529415,  0.23529415,\n",
       "        0.23529415,  0.23529415,  0.23529415,  0.23529415,  0.23529415,\n",
       "        0.23529415,  0.23529415,  0.23529415,  0.23529415,  0.23529415,\n",
       "        0.23529415], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squashed[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = K.random_normal((2, 10, 16))\n",
    "mask = K.variable(np.array([[1,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_265:0' shape=(?, ?) dtype=float32>"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.batch_flatten(x * K.expand_dims(mask, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1152, 10, 16)\n",
      "(12, 1152, 10, 16)\n",
      "(12, 1152, 10, 16)\n",
      "(12, 1152, 10)\n"
     ]
    }
   ],
   "source": [
    "B = K.zeros(shape=(12, 1152, 10))\n",
    "C =  K.map_fn(lambda x: K.softmax(x, axis=-1), B)\n",
    "\n",
    "x_batch = K.ones(shape=(12,1152, 8))\n",
    "x_batch = K.expand_dims(x_batch, axis=2)\n",
    "x_batch = K.repeat_elements(x_batch, rep=10, axis=2)\n",
    "y_batch = K.ones(shape=(1152, 10, 8, 16))\n",
    "xy_batch_dot = K.map_fn(lambda x: K.batch_dot(x, y_batch, axes=[2,2]), x_batch)\n",
    "\n",
    "C= K.expand_dims(C, axis=-1)\n",
    "C = K.repeat_elements(C, rep=16, axis=-1)\n",
    "\n",
    "print(K.int_shape(C))\n",
    "print(K.int_shape(xy_batch_dot))\n",
    "\n",
    "S = K.sum(C * xy_batch_dot, axis=1)\n",
    "S = K.expand_dims(S, axis=1)\n",
    "S = K.tile(S, [1,1152,1,1])\n",
    "# S = K.repeat_elements(S, rep=1152, axis=1)\n",
    "\n",
    "print(K.int_shape(S))\n",
    "new_B = K.sum(xy_batch_dot*S, axis=-1 )\n",
    "print(K.int_shape(new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_X = np.random.random((32,6,6,256))\n",
    "\n",
    "input_tensor = Input(shape=input_shape)\n",
    "reshaped = Reshape((36, 32, 8))(input_tensor)\n",
    "permuted = Permute((2,1,3))(reshaped)\n",
    "primary_caps = Reshape(output_shape)(permuted)\n",
    "digit_caps = CapsuleLayer(10, 16, num_groups=32)(primary_caps)\n",
    "\n",
    "model = Model(input_tensor, digit_caps)\n",
    "output = model.predict(dummy_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10, 16)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CapsuleLayer(10, 16)\n",
    "c.build((1,1152,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 10, 8, 16)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = CapsuleLayer(10, 16, num_groups=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2.build((1,1152,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = c2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
