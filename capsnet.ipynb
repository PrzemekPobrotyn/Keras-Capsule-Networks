{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras implementation of CapsNet\n",
    "##### `Dynamic Routing Between Capsules` by Sabour, Frosst and Hinton, in NIPS 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLAN:\n",
    "* implement reshaping 3D tensor (output of regular Conv2D into 32 6x6x8 capsules (or preferably, 32 36x8 capsules, so in fact make it (32x36)x8 **DONE**\n",
    "* implement a capsule layer with forward pass = dynamic routing\n",
    "    - implement squash function **DONE**\n",
    "    - implement weight sharing between capsules in each of 32 groups **LOOKS LIKE DONE? NO IDEA IF IT WORKS CORRECTLY THOUGH**\n",
    "    - implement dynamic routing **SEEMS DONE, BUT TWICE THERE SEEMS TO BE UNNECESSARY DIMS EXPANSION AND COPYING OF TENSORS. TRY FIXING THIS**\n",
    "* implement margin loss for digit existence **DONE**\n",
    "* implement reconstruction loss with masking for depending on learning phase\n",
    "* put it all together into a network\n",
    "* train on MNIST with small data augmentation as described in the paper, use `.fit_generator()`\n",
    "* reproduce paper results\n",
    "* visualize some reconstructions\n",
    "* visualize how reconstructions change with continous change of one of DigitCaps dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "Having read the paper again and its parameter count. I think my interpretation of weight sharing is incorrect and in fact each and every of 1152 capsules gets their own Wij matrix for every j, so there should be a total of 11520 weight matrcies of shape 8x16. Delete that later, but first do some experiments to see if your idea wouldn't result in similar performance at reduced cost.\n",
    "\n",
    "Also, since now each capsule gets its own 8x16 matrix, I don't think my reshaping into primary caps needs to be this complicated anymore. In other words, I don't need to retain the order in which the capsules are laid out in 1152 length vector since then each gets is own matrix anyway, since there is no sharing anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CapsNet Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import initializers, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Conv2D, Lambda, Dense, Flatten, Reshape\n",
    "from keras.engine.topology import Layer\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_train = x_train / 255.\n",
    "\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test / 255.\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_capsule_network(input_shape=(28, 28, 1)):\n",
    "    \n",
    "    # encoder network\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(kernel_size=(9,9), strides=(1,1), filters=256, activation='relu')(input_tensor)\n",
    "    primary_caps = PrimaryCaps(output_capsules=1152, capsule_dim=8, filters=256, kernel_size=(9,9), strides=(2,2))(conv1)\n",
    "    capsule_layer = CapsuleLayer(output_capsules=10, capsule_dim=16)(primary_caps)\n",
    "    lengths = Lambda(capsule_length, output_shape=(10,))(capsule_layer)\n",
    "    \n",
    " #  add a layer which in training selects the correct capsule and in test select the capsule with largest length\n",
    "    input_mask = Input(shape=(10,))\n",
    "    masked_from_labels = ReconstructionMask()([capsule_layer, input_mask])\n",
    "    masked_by_length = ReconstructionMask()(capsule_layer)\n",
    "  \n",
    "    # decoder network\n",
    "    decoder = Sequential(name='decoder')\n",
    "    decoder.add(Dense(512, activation='relu', input_shape=(16,)))\n",
    "    decoder.add(Dense(1024, activation='relu'))\n",
    "    decoder.add(Dense(784, activation='sigmoid'))\n",
    "    decoder.add(Reshape(input_shape))\n",
    "    \n",
    "    training_model = Model([input_tensor, input_mask], [lengths, decoder(masked_from_labels)])\n",
    "    inference_model = Model(input_tensor, [lengths, decoder(masked_by_length)])\n",
    "\n",
    "    return training_model, inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_X = np.random.random((1, 28, 28, 1))\n",
    "dummy_mask = np.array([0]*9 + [1]).reshape(1, 10)\n",
    "\n",
    "CapsNet = get_capsule_network()\n",
    "output = CapsNet.predict(dummy_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps = output[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = output[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "  128/60000 [..............................] - ETA: 1:19:16 - loss: 0.8100 - categorical_accuracy: 0.0703"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-491-35820a841a63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCapsNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmargin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mCapsNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Przemek/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/Przemek/anaconda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Przemek/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Przemek/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Przemek/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CapsNet.compile(loss=margin_loss(), optimizer='sgd', metrics=['categorical_accuracy'])\n",
    "CapsNet.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_142 (InputLayer)          (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 20, 20, 256)  20992       input_142[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 6, 6, 256)    5308672     conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_205 (Reshape)           (None, 1152, 8)      0           conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_206 (Reshape)           (None, 1152, 8)      0           reshape_205[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)             (None, 1152, 8)      0           reshape_206[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "capsule_layer_106 (CapsuleLayer (None, 10, 16)       1474560     lambda_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_143 (InputLayer)          (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction_mask_35 (Reconst (None, 16)           0           capsule_layer_106[0][0]          \n",
      "                                                                 input_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 512)          8704        reconstruction_mask_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 1024)         525312      dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_115 (Lambda)             (None, 10)           0           capsule_layer_106[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 784)          803600      dense_50[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 8,141,840\n",
      "Trainable params: 8,141,840\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CapsNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capsule_length(x):\n",
    "    length = K.sqrt(K.sum(K.square(x), axis=-1))\n",
    "    return length\n",
    "\n",
    "def squash(x):\n",
    "    l2_norm = K.sum(K.square(x), axis=-1, keepdims=True)\n",
    "    squash = l2_norm / (1 + l2_norm) * (x / (K.sqrt(l2_norm) + K.epsilon()))\n",
    "    return squash\n",
    "\n",
    "get_custom_objects().update({'squash': Activation(squash)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y pred is one hot encoded vector so of size (batch_size, num_classes)\n",
    "\n",
    "def margin_loss(lambda_=0.5, m_plus=0.9, m_minus=0.1):\n",
    "    def margin(y_true, y_pred):\n",
    "        loss = K.sum(\n",
    "            y_true * K.square(K.maximum(0., m_plus - y_pred)) + \n",
    "            lambda_ * (1 - y_pred) * K.square(K.maximum(0., y_pred - m_minus)),\n",
    "            axis=1,\n",
    "        )\n",
    "        return K.mean(loss)\n",
    "    return margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(y_true, y_pred):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrimaryCaps(\n",
    "    output_capsules, \n",
    "    capsule_dim,\n",
    "    filters,\n",
    "    kernel_size, \n",
    "    strides=(1,1),\n",
    "    padding='valid',\n",
    "):\n",
    "    \n",
    "    def eval_primary_caps(input_tensor):\n",
    "        \n",
    "        conv2d = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding)\n",
    "        x = conv2d(input_tensor)\n",
    "        reshaped = Reshape((-1, capsule_dim))(x)\n",
    "        output_tensor = Reshape((output_capsules, capsule_dim))(reshaped)\n",
    "        return Lambda(Activation('squash'))(output_tensor)\n",
    "\n",
    "    return eval_primary_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLayer(Layer):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        output_capsules, \n",
    "        capsule_dim, \n",
    "        routing_iterations=3, \n",
    "        kernel_initializer='glorot_uniform',\n",
    "        activation='squash',\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.output_capsules = output_capsules\n",
    "        self.capsule_dim = capsule_dim\n",
    "        self.routing_iterations = routing_iterations\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.activation=Activation(activation)\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=(\n",
    "                input_shape[1], \n",
    "                self.output_capsules, \n",
    "                input_shape[2], \n",
    "                self.capsule_dim,\n",
    "            ),\n",
    "            initializer=self.kernel_initializer,\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        super(CapsuleLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = K.expand_dims(x, axis=2)\n",
    "        x = K.repeat_elements(x, rep=self.output_capsules, axis=2)\n",
    "        U = K.map_fn(lambda x: K.batch_dot(x, self.kernel, axes=[2,2]), x)\n",
    "        \n",
    "        # initialize matrix of b_ij's\n",
    "        input_shape = K.shape(x)\n",
    "        B = K.zeros(shape=(input_shape[0], input_shape[1], self.output_capsules))\n",
    "        for i in range(self.routing_iterations):\n",
    "            V, B_updated = self._routing_single_iter(B, U, i, input_shape)\n",
    "            B = B_updated\n",
    "            \n",
    "        return V\n",
    "            \n",
    "    def _routing_single_iter(self, B, U, i, input_shape):\n",
    "        C = K.softmax(B, axis=-1)\n",
    "        C = K.expand_dims(C, axis=-1)\n",
    "        C = K.repeat_elements(C, rep=self.capsule_dim, axis=-1)\n",
    "        S = K.sum(C * U, axis=1)\n",
    "        V = self.activation(S)\n",
    "        if i != self.routing_iterations:\n",
    "            V_expanded = K.expand_dims(V, axis=1)\n",
    "            V_expanded = K.tile(V_expanded, [1, input_shape[1], 1, 1])\n",
    "            B = B + K.sum(U*V_expanded, axis=-1)\n",
    "        return V, B\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_capsules, self.capsule_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructionMask(Layer):\n",
    "    def call(self, input_):\n",
    "        if type(input_) == list and len(input_) == 2:\n",
    "            x = input_[0]\n",
    "            mask = input_[1]\n",
    "        else:\n",
    "            x = input_\n",
    "            len_x = K.sqrt(K.sum(K.square(input_), -1))\n",
    "            mask = K.one_hot(indices=K.argmax(len_x), num_classes=K.shape(x)[1])\n",
    "        \n",
    "        return tf.boolean_mask(x, mask, axis=0)\n",
    "    \n",
    "    def compute_output_shape(self, input_):\n",
    "        if type(input_) == list and len(input_) == 2:\n",
    "            input_shape = input_[0]\n",
    "            return (input_shape[0], input_shape[2])\n",
    "        else:\n",
    "            return (input_[0], input_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(\n",
    "[\n",
    "    [1,0,0,0,0,0,0,0,0,0], \n",
    "    [0,0,0,0,0,0,0,0,0,1]\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = K.random_normal((2, 10, 16))\n",
    "len_x = K.sqrt(K.sum(K.square(x), -1))\n",
    "mask = K.one_hot(indices=K.argmax(len_x), num_classes=K.shape(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot:0' shape=(2, ?) dtype=float32>"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Computes the one-hot representation of an integer tensor.\n",
       "\n",
       "# Arguments\n",
       "    indices: nD integer tensor of shape\n",
       "        `(batch_size, dim1, dim2, ... dim(n-1))`\n",
       "    num_classes: Integer, number of classes to consider.\n",
       "\n",
       "# Returns\n",
       "    (n + 1)D one hot representation of the input\n",
       "    with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K.one_hot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'boolean_mask_1/GatherV2:0' shape=(?, 16) dtype=float32>"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.boolean_mask(x, mask, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = K.random_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1152, 10, 16)\n",
      "(12, 1152, 10, 16)\n",
      "(12, 1152, 10, 16)\n",
      "(12, 1152, 10)\n"
     ]
    }
   ],
   "source": [
    "B = K.zeros(shape=(12, 1152, 10))\n",
    "C =  K.map_fn(lambda x: K.softmax(x, axis=-1), B)\n",
    "\n",
    "x_batch = K.ones(shape=(12,1152, 8))\n",
    "x_batch = K.expand_dims(x_batch, axis=2)\n",
    "x_batch = K.repeat_elements(x_batch, rep=10, axis=2)\n",
    "y_batch = K.ones(shape=(1152, 10, 8, 16))\n",
    "xy_batch_dot = K.map_fn(lambda x: K.batch_dot(x, y_batch, axes=[2,2]), x_batch)\n",
    "\n",
    "C= K.expand_dims(C, axis=-1)\n",
    "C = K.repeat_elements(C, rep=16, axis=-1)\n",
    "\n",
    "print(K.int_shape(C))\n",
    "print(K.int_shape(xy_batch_dot))\n",
    "\n",
    "S = K.sum(C * xy_batch_dot, axis=1)\n",
    "S = K.expand_dims(S, axis=1)\n",
    "S = K.tile(S, [1,1152,1,1])\n",
    "# S = K.repeat_elements(S, rep=1152, axis=1)\n",
    "\n",
    "print(K.int_shape(S))\n",
    "new_B = K.sum(xy_batch_dot*S, axis=-1 )\n",
    "print(K.int_shape(new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_X = np.random.random((32,6,6,256))\n",
    "\n",
    "input_tensor = Input(shape=input_shape)\n",
    "reshaped = Reshape((36, 32, 8))(input_tensor)\n",
    "permuted = Permute((2,1,3))(reshaped)\n",
    "primary_caps = Reshape(output_shape)(permuted)\n",
    "digit_caps = CapsuleLayer(10, 16, num_groups=32)(primary_caps)\n",
    "\n",
    "model = Model(input_tensor, digit_caps)\n",
    "output = model.predict(dummy_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10, 16)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CapsuleLayer(10, 16)\n",
    "c.build((1,1152,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 10, 8, 16)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = CapsuleLayer(10, 16, num_groups=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2.build((1,1152,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = c2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
